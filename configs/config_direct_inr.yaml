comments:  

method: direct_inr
data:
  dataset_name:  &dataset_name your_datasetname
  undersampling:
    type: rosette #poisson #fullysampled #poisson #fullysampled
    accel: 4.1 #8.07 #4.1 #12.09
    full_kcenter: 100 #bigger number means less fully sampled k-space center (1:full_kcenter)
  save_dir: ./results


# JBM note: I think these get overwritten later 
network:
  encoding: hashgrid
  encoding_params:
    otype: Grid
    type: Hash
    n_levels: 16
    n_features_per_level: 2
    log2_hashmap_size: 20
    base_resolution: 16
    per_level_scale: 1.26 #(default), #1.22, #1.32, #1.26 #1.5  16*1.26^15 ~= 512
    interpolation: linear
  model_type: mlp
  in_dim: 2
  hidden_dims: [128, 128, 128, 128] # NOTE: models can stall out for up to a couple of hundred epochs
  # hidden_dims: [256, 256, 256, 256, 256]



training:
  opt_type: &opt_type adam
  train_iters: &train_iters 300 # was 200
  train_tol: &train_tol 1e-6
  train_loss: &train_loss  weighted_k_mse
  train_lr: &train_lr 1e-2
  train_batch_size: &train_batch_size  1
  weight_decay: &weight_decay 0 # TODO: this seems to be broken for larger values? 
  # stalls out at values that I was able to get it to perform ok at by just hard-coding
  # weight decay in _get_optimizer() in direct_inr.py


  train:
      enabled: false
      n_epochs: *train_iters
      batch_size: *train_batch_size
      loss: 
        type: *train_loss
      optimizer:
        type: *opt_type
        lr: *train_lr
        weight_decay: *weight_decay
      tol: *train_tol

hydra:
  run:
    dir: .
